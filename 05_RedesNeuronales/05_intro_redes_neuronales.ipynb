{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicios del libro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. TensorFlow Playground es un simulador de redes neuronales muy útil, creado por el equipo de TensorFlow. En este ejercicio, enterarás varios clasficadores binarios con unos pocos clics y ajustarás la arquitectura del modelo y sus hierparámetros para intuir como funcioan las redes neuonales y que hacen sus hiperparametros. Tómtate tu tiempo para explorar lo siguiente:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Los patrones que aprende una red neuronal. Prueba a entrenar la red predeterminadara haciendo clic en el botín Run. Observa como enseguida encuentra una solución para la tarea de clasificación. Las neuronas de la primera capa oculta han aprendido a combinar los patrones sencillos de laprimera en patrones más complejos. En general, cuantas más capas hay, más complejo puede ser el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Las funciones de activación. Prueba a sustituir la función de activación tanh por una ReLU y entrena la red de nuevo. Observa que encuentra una solución más deprisa todavía, pero esta vez los límimtes son lineales. Esto se debe a la forma de la función ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- El riesgo de mínimos locales. Modifica la arquitectura de la red para tener una sola capa oculta con tres neuronas. Enténala varias veces(para reiniciar los pesso de la red, hazx clic en el botón Reset, junto a Play). Observa que el tiempo de entrenamiento cambia mucho y, a veces, incluso se atasca en un mínimo local."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lo que pasa cuando las redes neuronales son demasiado pequeñas. Quita una neurona para dejar solo dos. Observa que ahora la red neuronal es incapaz de encontrar una buena solución, auqneu pruebes varias veces. El modelo no tiene suficientes parámetros y subajusta sistematicamente el conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lo que pasa cuando las redes neuronales son bastante grandes. Configura el número de neuronas en ocho y entrena la red varias veces. Observa que ahora es consistentemente rápida y no se atasca nunca. Esto subraya un hallazgo importante en la teoría de redes neuronales: las redes neuronales grandes casi nunca se atascan en mínimos locales, y si lo hacen, estos óptimos locales son casi tan buenos como el óptimo global. Sin embargo, pueden seguir atascándose en mesetas largas durante mucho tiempo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- El reistgo de desvanecimiento del gradiente en redes profundas. Selecciona el conjunto de datos spiral y cambiala arquitectura de la red para tener cuatro capas ocultas con ocho neuronas cada una. Observa que el entrenamiento tarda mucho más y a menudo se atasca en mesetas durante periodos de tiempo largos. Observa también que las neuronlas de las capas más altas tienden a evolucionar más deprisa que las neuronas de las capas inferiores- Este problema llamado \"desvanecimiento del gradiente\" se puede paliar con una mejor incialización de pesos y otras técnicas mejores optimizadores o normalización de lotes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ve más lejos. Tómate una hora más o menos para nugar con otros parámetros y hacerte una idea de lo que hacen, consigue una comprensión intuitiva de las redes neuronales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. ¿Por qué suele ser preferible usar un clasificador de regresión logística en vez de un perceptrón clásico (es decir, una sola capa de unidades lógicas de umbral entrenada con el algoritmo de entrenamiento Perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Un perceptrón clásico convergerá solo si el conjunto de datos es separable linealmente y no podrá estimar probabilidades de clase. Por el contrario, un clasificador de regresión logística convergerá en una solución buena, incluso aunque el conjunto de datos no sea separable linealmente, y generará probabilidades de clase.\n",
    "\n",
    "- ¿Cómo se puede ajustar un perceptrón para hacer que equivalga a un clasificador de regresión logística?\n",
    "    \n",
    "    Si cambias la función de activación del perceptrón porla función de activacción logística (o por la función de activación softmax si hay neuronas) y  lo entrenas con descenso de gradiente (u otro algoritmo de optimización que minimce la función de pérdida, por lo general entropía cruzada), será equivalente a un clasificador de regresión logística."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. ¿Por qué la función de activación logística es un ingrediente fundamental en el entreanmiento de los primeros PMC?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    La función de activación logística fue un ingrediente fundamental del entrenamiento de los primeros PMC, ya que su derivada nunca es cero, de manera que el descenso de gradiente puede tomar siempre la pendiente. Cuando la función de activación es una función escalonada, el descenso de gradiente no puede moverse,así que no hay pendiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Nombra tres funciones de activación populares ¿puedes dibujarlas?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las funciones de activación más populares incluyen la función escalonada, la función logística (sigmoide), la función tangente hiperbólica (tanh) y la función ReLU (Rectified Linear Unit)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicios de clase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Ventajas y desventajas del perceptrón multicapa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ventajas\n",
    "    - Capability to learn non-linear models\n",
    "    - Capability to learn models in real-time (on-line learning) using partial_fit\n",
    "- Desventajas\n",
    "    - PMC with hidden layers have non-convexloss function where there exists more than one local mijnimum. Therefore different random weight initializations can lead to different validation accuracy\n",
    "    - PMC requires tuning a number of hyperparameters such as the number of hidden neurons, layers, and iterations\n",
    "    - PMC is sentitive to feature scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. ¿Cuál es la complejidad computacional del perceptrón multicapa?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose there are $n$ training samples, $m$ features, $k$ hidden layers, each containing $h$ neurons - for simplicity, and  output neurons. The time complexity of backpropagation is \n",
    "$O(n·m·h^k·o·i)$, where $i$ is the number of iterations. Since backpropagation has a high time complexity, it is advisable to start with smaller number of hidden neurons and few hidden layers for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. ¿Qué transformación de los datos es conveniente para el perceptrón multicapa?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-layer Perceptron is sensitive to feature scaling, so it is highly recommended to scale your data. For example, scale each attribute on the input vector X to [0, 1] or [-1, +1], or standardize it to have mean 0 and variance 1. Note that you must apply the same scaling to the test set for meaningful results. You can use StandardScaler for standardization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler  # doctest: +SKIP\n",
    "scaler = StandardScaler()  # doctest: +SKIP\n",
    "# Don't cheat - fit only on training data\n",
    "scaler.fit(X_train)  # doctest: +SKIP\n",
    "X_train = scaler.transform(X_train)  # doctest: +SKIP\n",
    "# apply same transformation to test data\n",
    "X_test = scaler.transform(X_test)  # doctest: +SKIP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative and recommended approach is to use StandardScaler in a Pipeline\n",
    "\n",
    "- Finding a reasonable regularization parameter $\\alpha$ is best done using GridSearchCV, usually in the range 10.0 ** -np.arange(1, 7).\n",
    "\n",
    "- Empirically, we observed that L-BFGS converges faster and with better solutions on small datasets. For relatively large datasets, however, Adam is very robust. It usually converges quickly and gives pretty good performance. SGD with momentum or nesterov’s momentum, on the other hand, can perform better than those two algorithms if learning rate is correctly tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
