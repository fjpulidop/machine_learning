{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación del entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"decision_trees\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Solving environment: ...working... done\n",
      "\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conda install python-graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificación en árboles de decisión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los árboles de decisión (decision trees) también permiten la clasificación y la regresión, se basan en grafos con estructura de árboles. Los árboles de decisión son modelos del tipo denominado de “caja blanca”, son intuitivos y fáciles de interpretar y entran dentro de la denominada Inteligencia Artificial explicable, por contra los resultados obtenidos de un modelo de “caja negra” hay que admitirlos per se, no son explicables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenar y visualizar árboles de decisión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para entender los árboles de decisión, vamos a construir uno para ver cómo hace las predicciones.\n",
    "\n",
    "Vamos a ver cómo visualizar los árboles usando los datos de flores iris ya comentados en KNN pero usando las medidas de los pétalos en lugar de la de los sépalos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[:, 2:] # petal length and width\n",
    "y = iris.target\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(max_depth=2)\n",
    "tree_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos visualizar el árbol de decisión usando primero el método export_graphviz() para producir un archivo de definicion gráfico llamado iris_tree.dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: Tree Pages: 1 -->\r\n",
       "<svg width=\"363pt\" height=\"314pt\"\r\n",
       " viewBox=\"0.00 0.00 363.00 314.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 310)\">\r\n",
       "<title>Tree</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-310 359,-310 359,4 -4,4\"/>\r\n",
       "<!-- 0 -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\r\n",
       "<path fill=\"#ffffff\" stroke=\"black\" d=\"M216.5,-306C216.5,-306 66.5,-306 66.5,-306 60.5,-306 54.5,-300 54.5,-294 54.5,-294 54.5,-235 54.5,-235 54.5,-229 60.5,-223 66.5,-223 66.5,-223 216.5,-223 216.5,-223 222.5,-223 228.5,-229 228.5,-235 228.5,-235 228.5,-294 228.5,-294 228.5,-300 222.5,-306 216.5,-306\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"141.5\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal length (cm) &lt;= 2.45</text>\r\n",
       "<text text-anchor=\"middle\" x=\"141.5\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.667</text>\r\n",
       "<text text-anchor=\"middle\" x=\"141.5\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 150</text>\r\n",
       "<text text-anchor=\"middle\" x=\"141.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [50, 50, 50]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"141.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = setosa</text>\r\n",
       "</g>\r\n",
       "<!-- 1 -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>1</title>\r\n",
       "<path fill=\"#e58139\" stroke=\"black\" d=\"M109,-179.5C109,-179.5 12,-179.5 12,-179.5 6,-179.5 0,-173.5 0,-167.5 0,-167.5 0,-123.5 0,-123.5 0,-117.5 6,-111.5 12,-111.5 12,-111.5 109,-111.5 109,-111.5 115,-111.5 121,-117.5 121,-123.5 121,-123.5 121,-167.5 121,-167.5 121,-173.5 115,-179.5 109,-179.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"60.5\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"60.5\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 50</text>\r\n",
       "<text text-anchor=\"middle\" x=\"60.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [50, 0, 0]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"60.5\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = setosa</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;1 -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;1</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M113.397,-222.907C105.605,-211.652 97.1358,-199.418 89.3043,-188.106\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"92.0315,-185.897 83.4617,-179.667 86.2762,-189.881 92.0315,-185.897\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"78.9896\" y=\"-200.564\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\r\n",
       "</g>\r\n",
       "<!-- 2 -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>2</title>\r\n",
       "<path fill=\"#ffffff\" stroke=\"black\" d=\"M295.5,-187C295.5,-187 151.5,-187 151.5,-187 145.5,-187 139.5,-181 139.5,-175 139.5,-175 139.5,-116 139.5,-116 139.5,-110 145.5,-104 151.5,-104 151.5,-104 295.5,-104 295.5,-104 301.5,-104 307.5,-110 307.5,-116 307.5,-116 307.5,-175 307.5,-175 307.5,-181 301.5,-187 295.5,-187\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"223.5\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal width (cm) &lt;= 1.75</text>\r\n",
       "<text text-anchor=\"middle\" x=\"223.5\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"223.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 100</text>\r\n",
       "<text text-anchor=\"middle\" x=\"223.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 50, 50]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"223.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;2 -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>0&#45;&gt;2</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M169.949,-222.907C176.183,-214.014 182.844,-204.509 189.277,-195.331\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"192.228,-197.219 195.101,-187.021 186.495,-193.201 192.228,-197.219\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"199.431\" y=\"-207.943\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\r\n",
       "</g>\r\n",
       "<!-- 3 -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>3</title>\r\n",
       "<path fill=\"#4de88e\" stroke=\"black\" d=\"M204,-68C204,-68 101,-68 101,-68 95,-68 89,-62 89,-56 89,-56 89,-12 89,-12 89,-6 95,-0 101,-0 101,-0 204,-0 204,-0 210,-0 216,-6 216,-12 216,-12 216,-56 216,-56 216,-62 210,-68 204,-68\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"152.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.168</text>\r\n",
       "<text text-anchor=\"middle\" x=\"152.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 54</text>\r\n",
       "<text text-anchor=\"middle\" x=\"152.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 49, 5]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"152.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\r\n",
       "</g>\r\n",
       "<!-- 2&#45;&gt;3 -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>2&#45;&gt;3</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M197.062,-103.726C191.385,-94.9703 185.376,-85.7032 179.671,-76.9051\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"182.469,-74.786 174.092,-68.2996 176.595,-78.5943 182.469,-74.786\"/>\r\n",
       "</g>\r\n",
       "<!-- 4 -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>4</title>\r\n",
       "<path fill=\"#843de6\" stroke=\"black\" d=\"M343,-68C343,-68 246,-68 246,-68 240,-68 234,-62 234,-56 234,-56 234,-12 234,-12 234,-6 240,-0 246,-0 246,-0 343,-0 343,-0 349,-0 355,-6 355,-12 355,-12 355,-56 355,-56 355,-62 349,-68 343,-68\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"294.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.043</text>\r\n",
       "<text text-anchor=\"middle\" x=\"294.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 46</text>\r\n",
       "<text text-anchor=\"middle\" x=\"294.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1, 45]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"294.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\r\n",
       "</g>\r\n",
       "<!-- 2&#45;&gt;4 -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>2&#45;&gt;4</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M249.938,-103.726C255.615,-94.9703 261.624,-85.7032 267.329,-76.9051\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"270.405,-78.5943 272.908,-68.2996 264.531,-74.786 270.405,-78.5943\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x1d5b7b69b50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from graphviz import Source\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "export_graphviz(\n",
    "        tree_clf,\n",
    "        out_file=os.path.join(IMAGES_PATH, \"iris_tree.dot\"),\n",
    "        feature_names=iris.feature_names[2:],\n",
    "        class_names=iris.target_names,\n",
    "        rounded=True,\n",
    "        filled=True\n",
    "    )\n",
    "\n",
    "Source.from_file(os.path.join(IMAGES_PATH, \"iris_tree.dot\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hacer predicciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imaginemos que encontramos una flor iris y queremos clasificarla. \n",
    "\n",
    "- Empezamos por el nodo raíz (profundidad 0, arriba): este nodo pregunta si la longitud del pétalo de la flor es inferior a 2,45 cm. \n",
    "    - Si lo es , bajamos al nodo hijo de la izquierda (profundidad 1, izquierda). En este caso, se trata de un \"nodo terminal\" (es decir, no tiene nodos hijo), así que no formula ninguna pregunta: simplemente mira la clase predicha par ese nodo y veremos que el árbol de decisión predice que la flor es una Iris setosa (class = setosa).\n",
    "\n",
    "Ahora imaginemos que nos encontramos otra flor y, esta vez, la longitud del pétalo es mayor que 2,45 cm. \n",
    "\n",
    "- Tenemos que bajar por el nodo hijo de la derecha (profundidad 1, derecha), que como no es un nodo terminal, hace otra pregunta: \n",
    "    - ¿es la anchiura del pétalo menor que 1,75 cm? \n",
    "           - Si lo es, es muy probable que la flor sea un Iris versicolor (profundidad 2, izquierda). \n",
    "           - Si no lo es, seguramente sea un Iris virginica (profundidad 2, derecha)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nota\n",
    "Una de las múltiples cualidades de los árboles de decisión es que requieren muy poca preparación de los datos. De hecho, no requieren escalado de características ni centrado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- El atributo ``samples`` de un nodo cuenta a cuántas instancias de entrenamiento se aplica. Por ejemplo,100 instancias de entrenamiento tienen una longitud de pétalo de más de 2,45 cm (profundidad 1, derecha) y, de esas 100, 54 tienen una anchura de pétalo de menos de 1,75 cm (profundidad 2, izquierda). \n",
    "\n",
    "- El atributo ``value`` de un nodo indica a cuántas instancias de entrenamiento de cada clase se aplica el nodo: por ejemplo, el nodo de abajo a la dercha se aplica a 0 Iris setosa, 1 Iris versicolor y 45 Iris virginica. \n",
    "\n",
    "- Por último, el atributo ``gini`` de un nodo mide su impureza: un nodo es \"puro\" (gini=0) si todas las instancias de entrenamiento a las que se aplica pertenecen a la misma clase. Por ejemplo, dado que el nodo de profundidad 1 solo se aplica a instancias de entranmiento Iris setosa, es puro y su puntuación ```gini = 0```. \n",
    "\n",
    "La siguiente ecuación muestra como el algoritmo de entrenamiento computa la puntuación ```gini```$G_i$ del $i_º$ nodo. El nodo izquierdo de profundidad 2 tiene una puntuación ```gini``` igual a $1- (0/54)^2 - (49/54)^2 - (5/54)^2 \\approx 0,168$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "G_i = 1 - \\sum_{k=1}^n P_i,k^2\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta ecuación:\n",
    "\n",
    "- $P_i,k$ es el ratio de instancias de clase ```k``` entre las instancias de entrenamiento del $i_º$ nodo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nota\n",
    "Scikit-learn utiliza el algoritmo CART que solo produce árboles binarios, sin embargo hay otros algoritmos como los ID3 que pueden producir árboles de decisión con nodos que tengan más de dos hijos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente imagen nos muestra los límites de decisión de este árbol.\n",
    "\n",
    "- La línea gruesa representa el límite de decisión del nodo raíz (profundidad 0): longitud de pétalo = 2,45 cm.\n",
    "\n",
    "- Como el área de la izquierda es pura (solo Iris setosa), ya no puede divirise más.\n",
    "\n",
    "- En cambio el área de la derecha es impura, así que el nodo derecho de profundidad 1 se divide en anchura de pétalo = 1,75 cm (representado por la línea de guiones). \n",
    "\n",
    "- Dado que max_depth era 2, el árbol de decisión se tiene justo ahí. Si configuramos max_depth = 3, los dos nodos de profundidad 2 añadirían cada uno otro límite de decisión (representado por las líneas de puntos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure decision_tree_decision_boundaries_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "def plot_decision_boundary(clf, X, y, axes=[0, 7.5, 0, 3], iris=True, legend=False, plot_training=True):\n",
    "    x1s = np.linspace(axes[0], axes[1], 100)\n",
    "    x2s = np.linspace(axes[2], axes[3], 100)\n",
    "    x1, x2 = np.meshgrid(x1s, x2s)\n",
    "    X_new = np.c_[x1.ravel(), x2.ravel()]\n",
    "    y_pred = clf.predict(X_new).reshape(x1.shape)\n",
    "    custom_cmap = ListedColormap(['#fafab0','#9898ff','#a0faa0'])\n",
    "    plt.contourf(x1, x2, y_pred, alpha=0.3, cmap=custom_cmap)\n",
    "    if not iris:\n",
    "        custom_cmap2 = ListedColormap(['#7d7d58','#4c4c7f','#507d50'])\n",
    "        plt.contour(x1, x2, y_pred, cmap=custom_cmap2, alpha=0.8)\n",
    "    if plot_training:\n",
    "        plt.plot(X[:, 0][y==0], X[:, 1][y==0], \"yo\", label=\"Iris setosa\")\n",
    "        plt.plot(X[:, 0][y==1], X[:, 1][y==1], \"bs\", label=\"Iris versicolor\")\n",
    "        plt.plot(X[:, 0][y==2], X[:, 1][y==2], \"g^\", label=\"Iris virginica\")\n",
    "        plt.axis(axes)\n",
    "    if iris:\n",
    "        plt.xlabel(\"Petal length\", fontsize=14)\n",
    "        plt.ylabel(\"Petal width\", fontsize=14)\n",
    "    else:\n",
    "        plt.xlabel(r\"$x_1$\", fontsize=18)\n",
    "        plt.ylabel(r\"$x_2$\", fontsize=18, rotation=0)\n",
    "    if legend:\n",
    "        plt.legend(loc=\"lower right\", fontsize=14)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plot_decision_boundary(tree_clf, X, y)\n",
    "plt.plot([2.45, 2.45], [0, 3], \"k-\", linewidth=2)\n",
    "plt.plot([2.45, 7.5], [1.75, 1.75], \"k--\", linewidth=2)\n",
    "plt.plot([4.95, 4.95], [0, 1.75], \"k:\", linewidth=2)\n",
    "plt.plot([4.85, 4.85], [1.75, 3], \"k:\", linewidth=2)\n",
    "plt.text(1.40, 1.0, \"Depth=0\", fontsize=15)\n",
    "plt.text(3.2, 1.80, \"Depth=1\", fontsize=13)\n",
    "plt.text(4.05, 0.5, \"(Depth=2)\", fontsize=11)\n",
    "\n",
    "save_fig(\"decision_tree_decision_boundaries_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ventajas VS Desventajas\n",
    "\n",
    "Algunas ventajas de los árboles de decisión son:\n",
    "\n",
    "- Sencillo de entender e interpretar. Los árboles se pueden visualizar.\n",
    "\n",
    "- Requiere poca preparación de datos. Otras técnicas a menudo requieren la normalización de datos, es necesario crear variables ficticias y eliminar valores en blanco. Sin embargo, tenga en cuenta que este módulo no admite valores perdidos.\n",
    "\n",
    "- El costo de usar el árbol (es decir, predecir datos) es logarítmico en el número de puntos de datos usados para entrenar el árbol.\n",
    "\n",
    "- Capaz de manejar datos tanto numéricos como categóricos. Otras técnicas suelen estar especializadas en analizar conjuntos de datos que tienen un solo tipo de variable.\n",
    "\n",
    "- Capaz de manejar problemas de múltiples salidas.\n",
    "\n",
    "- Utiliza un modelo de caja blanca. Si una situación dada es observable en un modelo, la explicación de la condición se explica fácilmente mediante lógica booleana. Por el contrario, en un modelo de caja negra (por ejemplo, en una red neuronal artificial), los resultados pueden ser más difíciles de interpretar.\n",
    "\n",
    "- Posible validar un modelo mediante pruebas estadísticas. Eso permite tener en cuenta la fiabilidad del modelo.\n",
    "\n",
    "- Se desempeña bien incluso si el modelo real a partir del cual se generaron los datos viola sus suposiciones.\n",
    "\n",
    "Las desventajas de los árboles de decisión incluyen:\n",
    "\n",
    "- Los aprendices de árboles de decisiones pueden crear árboles demasiado complejos que no generalizan bien los datos. Esto se llama sobreajuste. Para evitar este problema son necesarios mecanismos como la poda, el establecimiento del número mínimo de muestras necesarias en un nodo de la hoja o el establecimiento de la profundidad máxima del árbol.\n",
    "\n",
    "- Los árboles de decisión pueden ser inestables porque pequeñas variaciones en los datos pueden resultar en la generación de un árbol completamente diferente. Este problema se mitiga mediante el uso de árboles de decisión dentro de un conjunto.\n",
    "\n",
    "- Se sabe que el problema de aprender un árbol de decisión óptimo es NP-completo en varios aspectos de la optimalidad e incluso para conceptos simples. En consecuencia, los algoritmos prácticos de aprendizaje del árbol de decisiones se basan en algoritmos heurísticos, como el algoritmo codicioso, donde se toman decisiones localmente óptimas en cada nodo. Dichos algoritmos no pueden garantizar la devolución del árbol de decisiones globalmente óptimo. Esto se puede mitigar entrenando varios árboles en un aprendiz de conjunto, donde las características y muestras se muestrean al azar con reemplazo.\n",
    "\n",
    "- Hay conceptos que son difíciles de aprender porque los árboles de decisión no los expresan fácilmente, como XOR, problemas de paridad o multiplexor.\n",
    "\n",
    "- Los aprendices del árbol de decisiones crean árboles sesgados si dominan algunas clases. Por lo tanto, se recomienda equilibrar el conjunto de datos antes de ajustarlo al árbol de decisiones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consejos de uso práctico\n",
    "- Los árboles de decisión tienden a sobreajustarse a los datos con una gran cantidad de características. Es importante obtener la proporción correcta de muestras con respecto al número de características, ya que es muy probable que un árbol con pocas muestras en un espacio de gran dimensión se sobreajuste.\n",
    "\n",
    "- Considere realizar la reducción de dimensionalidad ( PCA , ICA o selección de características ) de antemano para darle a su árbol una mejor oportunidad de encontrar características que sean discriminatorias.\n",
    "\n",
    "- Comprender la estructura del árbol de decisiones ayudará a obtener más información sobre cómo el árbol de decisiones hace predicciones, lo cual es importante para comprender las características importantes de los datos.\n",
    "\n",
    "- Visualice su árbol mientras entrena utilizando la export función. Use max_depth=3 como una profundidad de árbol inicial para tener una idea de cómo el árbol se ajusta a sus datos y luego aumente la profundidad.\n",
    "\n",
    "- Recuerde que la cantidad de muestras necesarias para poblar el árbol se duplica por cada nivel adicional al que crece el árbol. Use max_depth para controlar el tamaño del árbol para evitar el sobreajuste.\n",
    "\n",
    "- Utilice min_samples_splito min_samples_leaf para asegurarse de que varias muestras informan cada decisión en el árbol, controlando qué divisiones se considerarán. Un número muy pequeño generalmente significará que el árbol se ajustará en exceso, mientras que un número grande evitará que el árbol aprenda los datos. Pruébelo min_samples_leaf=5 como valor inicial. Si el tamaño de la muestra varía mucho, se puede utilizar un número flotante como porcentaje en estos dos parámetros. Si bien min_samples_split puede crear hojas arbitrariamente pequeñas, min_samples_leaf garantiza que cada hoja tenga un tamaño mínimo, evitando nodos de hojas de baja varianza y sobreajuste en problemas de regresión. Para la clasificación con pocas clases, min_samples_leaf=1 suele ser la mejor opción.\n",
    "\n",
    "- Equilibre su conjunto de datos antes del entrenamiento para evitar que el árbol esté sesgado hacia las clases dominantes. El balance de clases se puede hacer muestreando un número igual de muestras de cada clase, o preferiblemente normalizando la suma de los pesos de las muestras ( sample_weight) para cada clase al mismo valor. También tenga en cuenta que los criterios de prepoda basados en el peso, como min_weight_fraction_leaf, estarán menos sesgados hacia las clases dominantes que los criterios que no son conscientes de los pesos de la muestra, como min_samples_leaf.\n",
    "\n",
    "- Si se pesan las muestras, será más fácil optimizar la estructura del árbol utilizando un criterio de poda previa basado en el peso, como min_weight_fraction_leaf, que asegura que los nudos de las hojas contienen al menos una fracción de la suma total de los pesos de las muestras.\n",
    "\n",
    "- Todos los árboles de decisión utilizan np.float32 matrices internamente. Si los datos de entrenamiento no están en este formato, se realizará una copia del conjunto de datos.\n",
    "\n",
    "- Si la matriz de entrada X es muy escasa, se recomienda convertirla a escasa csc_matrix antes de llamar a ajuste y escasa csr_matrix antes de llamar a predecir. El tiempo de entrenamiento puede ser varios órdenes de magnitud más rápido para una entrada de matriz escasa en comparación con una matriz densa cuando las entidades tienen valores cero en la mayoría de las muestras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intepretación del modelo: caja blanca vs caja negra\n",
    "Los árboles de decisión son intuitivos y sus decisiones son fáciles de interpretar. Tales modelos se denominan modelos de caja blanca. En cambio, hay otros como los random forest o redes neuronales que se consideran por regla general de caja negra, es decir son difíciles de explicar en términos sencillos el por qué se han hecho las predicciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimación de probabilidades de clase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un árbol de decisión también puede estimar la probabilidad de que una instancia pertenezca a una clase k particular. Primero recorre el árbol para encontrar el nodo terminal para esta instancia y luego devuelve el ratio de instancias de entrenamiento de clase k en este nodo.\n",
    "\n",
    "Por ejemplo, aplicado a este caso se las flores, supongamos que hemos encontrado una flor con los pétalos de 5 cm de largo y 1,5 cm de ancho. El nodo terminal correspondiente es el de la izquierda de profundidad 2, asñí que el árbol de decisión deberñía sacar las siguientes probabilidades:\n",
    "\n",
    "- 0% para Iris setosa (0/54)\n",
    "- 90.7% para Iris versicolor (49/54)\n",
    "- 9.3% para Iris virginica (5/54).\n",
    "\n",
    "Y, si queremos que prediga la clase, debería mostrar Iris versicolor (clase 1) porque tiene la probabilidad más alta.\n",
    "\n",
    "Comprobación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.90740741, 0.09259259]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf.predict_proba([[5, 1.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf.predict([[5, 1.5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observemos que las probabilidades estimadas serían casi idénticas en cualquier otra parte del rectángulo de abajo a la derecha por ejemplo, si los pétalos midiesen 6 cm de largo y 1.5 cm de ancho."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmo de entrenamiento CART"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn utiliza el algoritmo ```C```lassification ```A```nd ```R```egression ```T```ree (CART) para entrenar árboles de decisión. \n",
    "\n",
    "Funciona dividiendo primero el conjunto de entrenamiento en dos subconjuntois mediante una única característica `` k`` y un umbral $t_k$ (por ejemplo, \"longitud del pétalo <=2,45 cm).\n",
    "\n",
    "¿Cómo elige k y $t_k$? Busca el par (k, $t_k$) que produce los subconjuntos más puros (ponderados por tamaño). La ecuación da la función de pérdida que el algoritmo intenta minimizar (libro página 201)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que el algoritmo CART ha conseguido dividir el conjunto de entrenamiento en dos, divide los subconjuntos empleando la misma lógica, después los sub-conjuntos y así sucesivamente. Deja de repetir la operación cuando alcanza la profundidad máxima (definida por el hyperparámetro max_depth) o si no puede encontrar una división que reduzca la impureza. Hay hyperparámetros que controla otras condiciones de detención (min_samples_leaf, min_weight_fraction_leaf y max_leaf_nodes).\n",
    "\n",
    "Esto puede producir que aunque tengamos un algoritmo razonadamente bueno en detección, puede que no sea óptimo...\n",
    "\n",
    "\n",
    "Por desgracia, se sabe que encontrar el árbol óptimo es un problema NP-completo (tiempo polinomial): requiere de un tiempo $O(exp(m))$, lo que hace el problema intrincado incluso con conjuntos de entrenamiento pequeños. Por eso debemos conformarnos con una solución \"razonablemente buena\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otros algoritmos de árboles de decisión: ID3, C4.5 y C5.0\n",
    "- ID3 (dicotomizador iterativo 3) fue desarrollado en 1986 por Ross Quinlan. El algoritmo crea un árbol de múltiples vías, encontrando para cada nodo (es decir, de manera codiciosa) la característica categórica que producirá la mayor ganancia de información para los objetivos categóricos. Los árboles crecen hasta su tamaño máximo y luego se suele aplicar un paso de poda para mejorar la capacidad del árbol de generalizar a datos invisibles.\n",
    "\n",
    "- C4.5 es el sucesor de ID3 y eliminó la restricción de que las características deben ser categóricas al definir dinámicamente un atributo discreto (basado en variables numéricas) que divide el valor del atributo continuo en un conjunto discreto de intervalos. C4.5 convierte los árboles entrenados (es decir, la salida del algoritmo ID3) en conjuntos de reglas si-entonces. Luego, se evalúa la precisión de cada regla para determinar el orden en que deben aplicarse. La poda se realiza eliminando la condición previa de una regla si la precisión de la regla mejora sin ella.\n",
    "\n",
    "- C5.0 es la última versión de Quinlan con licencia propietaria. Utiliza menos memoria y crea conjuntos de reglas más pequeños que C4.5 a la vez que es más preciso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complejidad computacional\n",
    "Hacer predicciones requiere atravesar el árbol de decisión desde la raíz hata un nodo terminal. Los árboles de decisión suelen ser aproximadamente equilibrados, así que atravesar uno requiere recorrer exhaustivamente $O(log_2(m))$ nodos. \n",
    "\n",
    "Dado que cada nodo requiere sólo comprobar el valor de una característica, la complejidad de predicción general es $O(log_2(m))$, independientemente del número de características- \n",
    "\n",
    "Así pues, las predicciones son muy rápidas incluso cuando se trata con conjuntos de entrenamiento grandes. El algoritmo de entrenamiento compara todas las características (o menos, si se configura ```max_features```) en todas las muestras en cada nodo. El resultado de comparr todas las características de todas las muestras de cada nodo es una complejidad de entranmiento de $O(n x m log_2(m))$.\n",
    "\n",
    "Para conjuntos de entrenamiento pequeños (menos de unos cuantos miles de instancias), sklearn puede acelear el entrenamiento preclasificando los datos (configurando ```pre sort = True```), pero eso ralentiza considerablemente el entrenamiento con conjuntos de datos más grandes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Impureza de Gini o entropía?\n",
    "Por defecto, se utiliza la medida de la impureza de Gini, pero podemos selecionar la entropía como medida de impureza configurando el hiperparam ```criterion``` como \"entropy\". \n",
    "\n",
    "El concepto de entropía se aproxima a cero cuando las moléculas está quietas y bien ordenadas. La entropía se extendió después a una amplia variedad de dominios, incluida la teoría de la información de Shannon, donde mide el contenido medio de información de un mensaje (la reducción de la entropía a menudo recibe el nombre de \"ganancia de información): la entropia es cero cuando todos los mensajes son idénticos.\n",
    "\n",
    "En machine learning, la entropía se utiliza con frecuencia como medida de impureza: la entropía de un conjunto es cero cuando contiene instancias de una sola clase.\n",
    "\n",
    "Entonces, ¿deberíamos utilizar la impureza de Gini o la entropía?. Lo cierto es que, la mayoría de las veces, no hay mucha diferencia: conducen a árboles similares. La impureza de Gini es ligeramente más rápida de computar, así que está bien como predeterminada. Sin embargo, cuando difieren, la impureza de Gini tiende a aislar la clase más frecuente en su propia rama del árbol, mientras que la entropía tiende a producir árboles algo más equilibrados."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
